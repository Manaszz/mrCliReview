# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ

## –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ—à–∏–±–æ–∫

### 1. CLI Execution Errors

#### 1.1. CLI Not Found

**–°–∏–º–ø—Ç–æ–º—ã**:
```
FileNotFoundError: [Errno 2] No such file or directory: 'cline'
```

**–ü—Ä–∏—á–∏–Ω—ã**:
- CLI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
- CLI –Ω–µ –≤ PATH
- –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Dockerfile

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞**:
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
docker exec code-review-api which cline
docker exec code-review-api cline --version

# –ü—Ä–æ–≤–µ—Ä–∫–∞ PATH
docker exec code-review-api env | grep PATH
```

**–†–µ—à–µ–Ω–∏–µ**:
```dockerfile
# Dockerfile - —É—Å—Ç–∞–Ω–æ–≤–∫–∞ CLI –≥–ª–æ–±–∞–ª—å–Ω–æ
RUN npm install -g @cline/cli
RUN npm install -g @qwen-code/qwen-code

# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –ª–æ–∫–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞
WORKDIR /app
RUN npm install @cline/cli
ENV PATH="/app/node_modules/.bin:${PATH}"
```

#### 1.2. CLI Timeout

**–°–∏–º–ø—Ç–æ–º—ã**:
```
asyncio.TimeoutError: CLI execution exceeded 300 seconds
```

**–ü—Ä–∏—á–∏–Ω—ã**:
- –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π MR (>10k lines)
- Model API –º–µ–¥–ª–µ–Ω–Ω–æ –æ—Ç–≤–µ—á–∞–µ—Ç
- –°–ª–æ–∂–Ω—ã–π –∫–æ–¥ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞**:
```python
# –õ–æ–≥–∏ –ø–æ–∫–∞–∂—É—Ç
logger.error(f"CLI timeout after {settings.REVIEW_TIMEOUT}s", extra={
    "project_id": 123,
    "mr_iid": 456,
    "mr_size_lines": 15000,  # –ë–æ–ª—å—à–æ–π MR
    "review_type": "architecture"  # –°–ª–æ–∂–Ω—ã–π —Ç–∏–ø
})
```

**–†–µ—à–µ–Ω–∏–µ**:

**A. –£–≤–µ–ª–∏—á–∏—Ç—å timeout**:
```python
# .env
REVIEW_TIMEOUT=600  # 10 –º–∏–Ω—É—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö MR
```

**B. –†–∞–∑–±–∏—Ç—å review –Ω–∞ —á–∞—Å—Ç–∏**:
```python
# ReviewService - chunking –¥–ª—è –±–æ–ª—å—à–∏—Ö MR
async def execute_review(self, request, repo_path):
    changed_files = await self.get_changed_files(repo_path)
    
    if len(changed_files) > 50:  # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ñ–∞–π–ª–æ–≤
        logger.info(f"Large MR detected: {len(changed_files)} files. Splitting into chunks.")
        chunks = self._split_into_chunks(changed_files, chunk_size=20)
        
        results = []
        for chunk in chunks:
            result = await self._review_chunk(chunk, request)
            results.append(result)
        
        return self._merge_results(results)
```

**C. Graceful degradation**:
```python
# Fallback –Ω–∞ –±—ã—Å—Ç—Ä—ã–µ review types –ø—Ä–∏ timeout
try:
    result = await cli_manager.execute_review(
        review_types=[ReviewType.ALL],
        timeout=300
    )
except asyncio.TimeoutError:
    logger.warning("Full review timed out, falling back to quick checks")
    result = await cli_manager.execute_review(
        review_types=[ReviewType.ERROR_DETECTION, ReviewType.SECURITY_AUDIT],
        timeout=120
    )
```

#### 1.3. CLI Out of Memory

**–°–∏–º–ø—Ç–æ–º—ã**:
```
Process was killed (OOM)
CLI stderr: "JavaScript heap out of memory"
```

**–ü—Ä–∏—á–∏–Ω—ã**:
- Node.js heap size –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (512MB)
- –ë–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã –≤ MR

**–†–µ—à–µ–Ω–∏–µ**:
```bash
# –£–≤–µ–ª–∏—á–∏—Ç—å Node.js heap
export NODE_OPTIONS="--max-old-space-size=4096"  # 4GB

# –í Dockerfile
ENV NODE_OPTIONS="--max-old-space-size=4096"
```

```yaml
# K8s - —É–≤–µ–ª–∏—á–∏—Ç—å memory limits
resources:
  limits:
    memory: "4Gi"  # –í–º–µ—Å—Ç–æ 2Gi
```

#### 1.4. CLI Invalid Output

**–°–∏–º–ø—Ç–æ–º—ã**:
```
json.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
```

**–ü—Ä–∏—á–∏–Ω—ã**:
- CLI –≤–µ—Ä–Ω—É–ª non-JSON output
- CLI –Ω–∞–ø–µ—á–∞—Ç–∞–ª warnings/errors –≤ stdout
- CLI crash

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞**:
```python
logger.error("Failed to parse CLI output", extra={
    "raw_output": stdout.decode()[:1000],  # –ü–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤
    "stderr": stderr.decode()
})
```

**–†–µ—à–µ–Ω–∏–µ**:
```python
# Robust parsing –≤ ClineCLIManager
async def _parse_cli_output(self, stdout, stderr):
    output = stdout.decode('utf-8').strip()
    
    # –ü–æ–ø—ã—Ç–∫–∞ 1: –ß–∏—Å—Ç—ã–π JSON
    try:
        return json.loads(output)
    except json.JSONDecodeError:
        pass
    
    # –ü–æ–ø—ã—Ç–∫–∞ 2: JSON –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞
    json_start = output.find('{')
    json_end = output.rfind('}')
    if json_start != -1 and json_end != -1:
        json_str = output[json_start:json_end+1]
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            pass
    
    # –ü–æ–ø—ã—Ç–∫–∞ 3: Fallback –Ω–∞ –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    logger.warning(f"Could not parse CLI output, using fallback")
    return {
        "issues": [],
        "summary": "Review completed but output parsing failed",
        "raw_output": output[:500]
    }
```

### 2. Model API Errors

#### 2.1. API Unavailable (503, Connection Error)

**–°–∏–º–ø—Ç–æ–º—ã**:
```
httpx.ConnectError: Connection refused
or
httpx.HTTPStatusError: 503 Service Unavailable
```

**–ü—Ä–∏—á–∏–Ω—ã**:
- Model API server down
- Network issues
- API overloaded

**–†–µ—à–µ–Ω–∏–µ**:

**A. Retry —Å exponential backoff**:
```python
# –í BaseCLIManager
async def _call_model_api_with_retry(self, prompt, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = await self._call_model_api(prompt)
            return response
        except (httpx.ConnectError, httpx.HTTPStatusError) as e:
            if e.response.status_code == 503:
                wait_time = 2 ** attempt + random.uniform(0, 1)  # Exponential backoff —Å jitter
                logger.warning(f"Model API unavailable, retry {attempt+1}/{max_retries} after {wait_time:.1f}s")
                await asyncio.sleep(wait_time)
            else:
                raise
    
    raise Exception(f"Model API unavailable after {max_retries} retries")
```

**B. Fallback –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π endpoint**:
```python
# config.py
MODEL_API_URL_PRIMARY = "https://primary-api.example.com/v1"
MODEL_API_URL_SECONDARY = "https://backup-api.example.com/v1"

# –í ClineCLIManager
async def _call_model_api(self, prompt):
    try:
        return await self._call_api(self.primary_url, prompt)
    except Exception as e:
        logger.warning(f"Primary API failed: {e}, trying secondary")
        return await self._call_api(self.secondary_url, prompt)
```

**C. Circuit breaker pattern**:
```python
from circuitbreaker import circuit

@circuit(failure_threshold=5, recovery_timeout=60)
async def call_model_api(self, prompt):
    # –ü–æ—Å–ª–µ 5 failed attempts, –æ—Ç–∫—Ä—ã—Ç—å circuit –Ω–∞ 60 —Å–µ–∫—É–Ω–¥
    # –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –±—É–¥—É—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ rejected –±–µ–∑ –ø–æ–ø—ã—Ç–∫–∏ –≤—ã–∑–æ–≤–∞
    return await self._call_api(self.api_url, prompt)
```

#### 2.2. Rate Limiting (429)

**–°–∏–º–ø—Ç–æ–º—ã**:
```
httpx.HTTPStatusError: 429 Too Many Requests
Headers: {'Retry-After': '60'}
```

**–†–µ—à–µ–Ω–∏–µ**:
```python
async def _handle_rate_limit(self, response):
    retry_after = int(response.headers.get('Retry-After', 60))
    logger.warning(f"Rate limited, waiting {retry_after}s")
    
    # Exponentially decrease parallel tasks
    self.parallel_tasks = max(1, self.parallel_tasks // 2)
    logger.info(f"Reduced parallel tasks to {self.parallel_tasks}")
    
    await asyncio.sleep(retry_after)
    
    # Retry request
    return await self._call_model_api(prompt)
```

#### 2.3. Invalid API Key (401)

**–°–∏–º–ø—Ç–æ–º—ã**:
```
httpx.HTTPStatusError: 401 Unauthorized
```

**–†–µ—à–µ–Ω–∏–µ**:
```python
# Health check –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
@app.on_event("startup")
async def verify_api_key():
    try:
        response = await httpx.get(
            f"{settings.MODEL_API_URL}/models",
            headers={"Authorization": f"Bearer {settings.MODEL_API_KEY}"}
        )
        response.raise_for_status()
        logger.info("Model API key valid")
    except httpx.HTTPStatusError as e:
        logger.error(f"Invalid Model API key: {e}")
        # Alert DevOps
        await send_alert("Invalid Model API key", severity="critical")
        # –ù–µ –ø–∞–¥–∞—Ç—å, –Ω–æ –ø–æ–º–µ—á–∞—Ç—å service as unhealthy
        app.state.model_api_available = False
```

### 3. GitLab API Errors

#### 3.1. Insufficient Permissions (403)

**–°–∏–º–ø—Ç–æ–º—ã**:
```
gitlab.exceptions.GitlabCreateError: 403 Forbidden
```

**–ü—Ä–∏—á–∏–Ω—ã**:
- GitLab token –Ω–µ –∏–º–µ–µ—Ç –ø—Ä–∞–≤ –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ MR
- Token –Ω–µ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–æ–µ–∫—Ç—É

**–†–µ—à–µ–Ω–∏–µ**:
```python
# –ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å permissions
async def verify_gitlab_permissions(self):
    try:
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Ç–µ—Å—Ç–æ–≤–æ–º—É –ø—Ä–æ–µ–∫—Ç—É
        project = await self.client.get("/projects/test-project-id")
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å scope —Ç–æ–∫–µ–Ω–∞
        user = await self.client.get("/user")
        scopes = user.headers.get("X-Oauth-Scopes", "")
        
        required_scopes = ["api", "write_repository"]
        missing_scopes = [s for s in required_scopes if s not in scopes]
        
        if missing_scopes:
            logger.error(f"GitLab token missing scopes: {missing_scopes}")
            return False
        
        return True
    except Exception as e:
        logger.error(f"GitLab permission check failed: {e}")
        return False
```

#### 3.2. MR Already Exists

**–°–∏–º–ø—Ç–æ–º—ã**:
```
gitlab.exceptions.GitlabCreateError: Branch already has merge request
```

**–†–µ—à–µ–Ω–∏–µ**:
```python
# Idempotent MR creation
async def create_or_update_mr(self, project_id, source, target, title, description):
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ —Å–æ–∑–¥–∞—Ç—å
        mr = await self.client.post(f"/projects/{project_id}/merge_requests", {
            "source_branch": source,
            "target_branch": target,
            "title": title,
            "description": description
        })
        logger.info(f"MR created: !{mr['iid']}")
        return mr
    except gitlab.exceptions.GitlabCreateError as e:
        if "already has merge request" in str(e).lower():
            # MR —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–∞–π—Ç–∏ –∏ –æ–±–Ω–æ–≤–∏—Ç—å
            logger.info(f"MR already exists for {source} ‚Üí {target}, updating")
            mrs = await self.client.get(f"/projects/{project_id}/merge_requests", params={
                "source_branch": source,
                "target_branch": target,
                "state": "opened"
            })
            if mrs:
                mr = mrs[0]
                updated_mr = await self.client.put(
                    f"/projects/{project_id}/merge_requests/{mr['iid']}",
                    {"description": description}
                )
                logger.info(f"MR updated: !{updated_mr['iid']}")
                return updated_mr
        raise
```

### 4. Git Repository Errors

#### 4.1. Clone Failure (Authentication)

**–°–∏–º–ø—Ç–æ–º—ã**:
```
git clone failed: Authentication failed for 'https://gitlab.example.com/project.git'
```

**–†–µ—à–µ–Ω–∏–µ**:
```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å token –≤ clone URL
def get_authenticated_clone_url(self, project_data):
    clone_url = project_data['http_url_to_repo']
    
    # –í—Å—Ç–∞–≤–∏—Ç—å token –≤ URL
    parsed = urllib.parse.urlparse(clone_url)
    authenticated_url = parsed._replace(
        netloc=f"oauth2:{self.token}@{parsed.netloc}"
    )
    
    return urllib.parse.urlunparse(authenticated_url)
```

#### 4.2. Disk Space Full

**–°–∏–º–ø—Ç–æ–º—ã**:
```
OSError: [Errno 28] No space left on device
```

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞**:
```python
import shutil

def get_disk_usage(path="/tmp/review"):
    total, used, free = shutil.disk_usage(path)
    return {
        "total_gb": total // (2**30),
        "used_gb": used // (2**30),
        "free_gb": free // (2**30),
        "percent_used": (used / total) * 100
    }

logger.info("Disk usage", extra=get_disk_usage())
```

**–†–µ—à–µ–Ω–∏–µ**:
```python
# Cleanup —Å—Ç–∞—Ä—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–≤
async def cleanup_old_repositories(self, max_age_hours=2):
    import time
    now = time.time()
    
    for repo_dir in os.listdir(self.work_dir):
        repo_path = os.path.join(self.work_dir, repo_dir)
        mtime = os.path.getmtime(repo_path)
        age_hours = (now - mtime) / 3600
        
        if age_hours > max_age_hours:
            logger.info(f"Removing old repository: {repo_dir} (age: {age_hours:.1f}h)")
            shutil.rmtree(repo_path)

# –í—ã–∑—ã–≤–∞—Ç—å periodically
@app.on_event("startup")
async def start_cleanup_task():
    asyncio.create_task(periodic_cleanup())

async def periodic_cleanup():
    while True:
        await asyncio.sleep(3600)  # –ö–∞–∂–¥—ã–π —á–∞—Å
        await git_manager.cleanup_old_repositories(max_age_hours=2)
```

## Logging Best Practices

### Structured Logging

```python
from loguru import logger

# –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å extra –¥–ª—è structured fields
logger.info("Review started", extra={
    "correlation_id": correlation_id,
    "project_id": project_id,
    "mr_iid": mr_iid,
    "agent": agent.value,
    "review_types": [rt.value for rt in review_types]
})

# –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö - –≤–∫–ª—é—á–∞—Ç—å context
logger.error("CLI execution failed", extra={
    "command": command,
    "exit_code": process.returncode,
    "stderr": stderr.decode()[:500],  # Limit size
    "repo_path": repo_path
})
```

### Log Levels

- **DEBUG**: –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–∫–∞–∂–¥—ã–π —à–∞–≥ CLI, raw outputs)
- **INFO**: –ù–æ—Ä–º–∞–ª—å–Ω—ã–π flow (review started, MR created, completion)
- **WARNING**: –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã (timeout retry, rate limit, fallback)
- **ERROR**: –û—à–∏–±–∫–∏ —Å partial recovery (CLI failed –Ω–æ review –ø—Ä–æ–¥–æ–ª–∂–∏–ª—Å—è)
- **CRITICAL**: –§–∞—Ç–∞–ª—å–Ω—ã–µ –æ—à–∏–±–∫–∏ (service cannot start, invalid config)

### Correlation ID

```python
import uuid

# –ü—Ä–∏ –∫–∞–∂–¥–æ–º request —Å–æ–∑–¥–∞–≤–∞—Ç—å correlation_id
@router.post("/api/v1/review")
async def review(request: ReviewRequest):
    correlation_id = str(uuid.uuid4())
    
    # –ü–µ—Ä–µ–¥–∞–≤–∞—Ç—å –≤–µ–∑–¥–µ
    result = await review_service.execute_review(
        request, correlation_id=correlation_id
    )
    
    # –õ–æ–≥–∏ –±—É–¥—É—Ç —Å correlation_id
    # grep "abc-123-def-456" logs/*.log –ø–æ–∫–∞–∂–µ—Ç –≤–µ—Å—å flow
```

## Alerting

### Critical Alerts (PagerDuty/Slack)

```python
# –ö–æ–≥–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å critical alert:
- Model API down (>5 –º–∏–Ω—É—Ç)
- GitLab API unreachable
- Disk space <10%
- Memory >90%
- CLI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ

async def send_critical_alert(message, details):
    await slack.post_message(
        channel="#code-review-alerts",
        text=f"üö® CRITICAL: {message}",
        attachments=[{
            "color": "danger",
            "fields": [{"title": k, "value": v} for k, v in details.items()]
        }]
    )
    
    # –¢–∞–∫–∂–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ PagerDuty –µ—Å–ª–∏ production
    if settings.ENV == "production":
        await pagerduty.trigger_incident(
            title=message,
            severity="critical",
            details=details
        )
```

### Warning Alerts (Slack only)

```python
# –ö–æ–≥–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å warning:
- Rate limiting activated
- Fallback –Ω–∞ secondary API
- CLI timeout (–Ω–æ review –ø—Ä–æ–¥–æ–ª–∂–∏–ª—Å—è)
- High review duration (>3 min)

async def send_warning_alert(message, details):
    await slack.post_message(
        channel="#code-review-warnings",
        text=f"‚ö†Ô∏è WARNING: {message}",
        attachments=[{
            "color": "warning",
            "fields": [{"title": k, "value": v} for k, v in details.items()]
        }]
    )
```

## Metrics & Monitoring

### Prometheus Metrics

```python
from prometheus_client import Counter, Histogram, Gauge

# Errors
cli_errors = Counter(
    'cli_errors_total',
    'Total CLI errors',
    ['agent', 'error_type']  # error_type: timeout, oom, parse_error
)

model_api_errors = Counter(
    'model_api_errors_total',
    'Model API errors',
    ['status_code', 'endpoint']
)

gitlab_api_errors = Counter(
    'gitlab_api_errors_total',
    'GitLab API errors',
    ['method', 'status_code']
)

# Recovery
retries_total = Counter(
    'retries_total',
    'Total retries',
    ['operation', 'success']  # operation: cli, model_api, gitlab_api
)

fallbacks_total = Counter(
    'fallbacks_total',
    'Total fallbacks to secondary system',
    ['from', 'to']  # from: cline, to: qwen
)

# Disk usage
disk_usage_percent = Gauge(
    'disk_usage_percent',
    'Disk usage percentage',
    ['mount_point']
)
```

### Grafana Alerts

```yaml
# Alert: High Error Rate
- alert: HighCLIErrorRate
  expr: rate(cli_errors_total[5m]) > 0.1
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "High CLI error rate ({{ $value }} errors/sec)"

# Alert: Model API Down
- alert: ModelAPIDown
  expr: model_api_errors_total{status_code="503"} > 10
  for: 2m
  labels:
    severity: critical
  annotations:
    summary: "Model API appears to be down"

# Alert: Disk Space Low
- alert: DiskSpaceLow
  expr: disk_usage_percent{mount_point="/tmp/review"} > 90
  for: 5m
  labels:
    severity: critical
  annotations:
    summary: "Disk space critically low ({{ $value }}%)"
```

## Recovery Procedures

### Manual Recovery

#### 1. CLI Crash - Restart review
```bash
# –ù–∞–π—Ç–∏ failed review
kubectl logs -n code-review deployment/code-review-api | grep "ERROR.*CLI execution failed"

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —á–µ—Ä–µ–∑ API
curl -X POST http://code-review.example.com/api/v1/review \
  -H "Content-Type: application/json" \
  -d '{
    "project_id": 123,
    "merge_request_iid": 456,
    "agent": "QWEN_CODE",  # Fallback –Ω–∞ –¥—Ä—É–≥–æ–π agent
    "review_types": ["ERROR_DETECTION", "SECURITY_AUDIT"]  # –¢–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ
  }'
```

#### 2. Disk Space Full - Cleanup
```bash
# –í—Ä—É—á–Ω—É—é —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ repos
kubectl exec -n code-review deployment/code-review-api -- \
  find /tmp/review -type d -mtime +1 -exec rm -rf {} \;

# –ò–ª–∏ —á–µ—Ä–µ–∑ API (–µ—Å–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å endpoint)
curl -X POST http://code-review.example.com/api/v1/admin/cleanup
```

#### 3. Model API Down - Wait and retry
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å Model API
curl -H "Authorization: Bearer $MODEL_API_KEY" \
  https://model-api.example.com/v1/models

# –ï—Å–ª–∏ down, –ø–æ–¥–æ–∂–¥–∞—Ç—å recovery –∏–ª–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –Ω–∞ backup
# –í .env –∏–∑–º–µ–Ω–∏—Ç—å MODEL_API_URL –Ω–∞ backup endpoint
kubectl set env deployment/code-review-api -n code-review \
  MODEL_API_URL=https://backup-model-api.example.com/v1

# Rollout restart
kubectl rollout restart deployment/code-review-api -n code-review
```

### Automatic Recovery

```python
# Graceful degradation –ø—Ä–∏ partial failures
async def execute_review_with_graceful_degradation(self, request, repo_path):
    results = {}
    failed_review_types = []
    
    for review_type in request.review_types:
        try:
            result = await self._execute_single_review(review_type, repo_path)
            results[review_type] = result
        except Exception as e:
            logger.error(f"Review type {review_type} failed: {e}")
            failed_review_types.append(review_type)
            # –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏
            continue
    
    if not results:
        # –í—Å–µ failed, raise error
        raise Exception(f"All review types failed: {failed_review_types}")
    
    # Partial success
    logger.warning(f"Partial review completed. Failed types: {failed_review_types}")
    return self._aggregate_results(results, failed_types=failed_review_types)
```

## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫

```python
# tests/test_error_handling.py

@pytest.mark.asyncio
async def test_cli_timeout_recovery():
    """Test CLI timeout triggers retry"""
    manager = ClineCLIManager(timeout=1)  # 1 second timeout
    
    with pytest.raises(asyncio.TimeoutError):
        await manager.execute_review(
            review_types=[ReviewType.ALL],
            repo_path="/large-repo"
        )
    
    # Verify retry was attempted
    assert manager.retry_count == 3

@pytest.mark.asyncio
async def test_model_api_fallback():
    """Test fallback to secondary API"""
    manager = ClineCLIManager(
        primary_api="http://down-api.com",
        secondary_api="http://working-api.com"
    )
    
    result = await manager.execute_review(...)
    
    # Should use secondary API
    assert manager.api_calls["secondary"] > 0
    assert result is not None

@pytest.mark.asyncio
async def test_graceful_degradation():
    """Test partial review completion"""
    # Mock one review type to fail
    with mock.patch.object(ClineCLIManager, '_execute_single_review') as mock_execute:
        mock_execute.side_effect = [
            ReviewRawResult(...),  # ERROR_DETECTION success
            Exception("CLI crashed"),  # SECURITY fail
            ReviewRawResult(...)  # REFACTORING success
        ]
        
        result = await review_service.execute_review(...)
        
        # Should have partial results
        assert len(result.issues) > 0
        assert "SECURITY_AUDIT" in result.failed_review_types
```


